## memory (langchain) component we will study in langgraph

## now we are gonna start to make Rag application using Langchain

- there are lot of components in rag base application , one of them is --> **Document loaders**

RAG is a technique that **combines information** (some other datasets particularly about and business) retrieval with language generation(llm), where a model retriveves relavant documents from a knowledgement base and then uses them as context to generate accurate and grounded responses.

Benefits of using RAG

1. Use of up-to-date information
2. Better privacy
3. No limit of document size (we divide those in chunkes)

eg;; let suppose we want to know current affare so most probabilly our llm will not give it's response bz it was trained any past time

--> ask about your personal data (like ask them about your person 100days before email)

## so all those situation where llm does not have data to response you , on those situation we used rag base application

## what we does :

--> we provide **external knowledge** base to our llm

--> now if a query come to llm and it does not know about that then it can go to that external knowledge to check is this context there.

## Rag components

-> Document Loaders
-> Text splitters
-> vector Database
-> Retrievers

# (we make any complex rag base application using these component)

## today is about Document loaders --> using it we can easily load document from any source

## Document loaders (in langchain there are 100+ document loaders)

impossible to learn all --> so --> we try to know **main concept**

## and 4 most useable document loaders

1. TextLoader
2. PyPDFLoader
3. WebBaseLoader
4. CSVLoader

## (Document Loaders) in Langchain::

document loader in langchain used to load data from various sources into a standardized format (usually as Document objects), which can then be used for Chunking, embedding, retrieval, and generation,

eg: so for rag application we need data and need to load it, and data can exsist at different sources
data can be pdf, text file , at any database, at any cloud ;; what our focus is to retrieve data from the source with a **good format** so that we can use it other component of langchain;; so you fetch data at any place it will show like a document format always

this is document format:

Document (
page_content= "The actual text content",
metadata = {"source":"filename.pdf", ...}
)

## Notes all document loaders are at lanchain_community

## (TextLoader)

TextLoader is a simple and commonly used document loader in LangChain that reads plain text (.txt) files and converts them into langchain document object

Use Case

- Ideal for loading chat logs, scraped text, transcripts, code snippeds, or any plain text data into a langchain pipeline

Limitation

- Works only with .txt files

## steps

1. make loader object
2. inside it as input you have to give the path of that .txt file

## Most userful Loader --> ## PyPDFLoader

-> PyPDFLoader is a document loader in langchain used to load content from PDF file and convert each page into document object

[
Document(page_content= "Text from page 1", metadata= {"page":0, "source":"file.pdf"}),
Document(page_cotent= "Text from page 2", metadata={"page":1, "source":"file.pdf"}),
......
]

Limitations:

- It uses the PyPDF library under the hood -- not great with scanned PDFs(which has photos etc) or complex layouts.

25 page pdf --> PyPDF --> list of 25 Documents object

Since PypdfLoader good for text pdf ;; but there some good loader for scanned pdf

eg:
pdfs with tables/columns --> PDFPlumberLoader
Scanned/Image PDFs --> UnstrucredPDFLoader or AmazonTextractPDFLoader
need layout and Image data --> PyMuPDFLoader
Want best structure extraction --> UnstructuredPDFLoader

## for more -> [text](https://docs.langchain.com/oss/python/integrations/document_loaders)

### what if you have a folder in it multiple txt files and pdf files are there: and you have to load all those files at a time.

## use --> (DirectoryLoader)
-> DirectoryLoader is a document loader that lets you load multiple documents from a directory (folder) of files.

** = Recursive search through subfolders

Global Patter  | what it Loads

"**/*.txt"     | All .txt files in all subfolders
"*.pdf"        | All .pdf files in the directory
"data/*.csv"   | All .csv files in the data/ folder
"**/*"         | all files (any type, all folders)

## Note : for opening folder we will use DirectoryLoader but what kind of content it's page content according to that use import Loader (like PyPdfloader, or TextLoader etc)
steps
1. give **path** where that directory is
2. **glob** structure (what kind of structure files you want inside that direcltory)
3. **loader_cls** basically loader class (PyPDFLoader, TextLoader etc)

## what are problems with that 
1. loading i had only three pdf which took 3-4sec to load (basically it was retieving that pdf and putting to memory so we can easly use those directly) 
2. memory proble( if we have 10+ pdf then it will be very hard to load them) 

## for solving these problem langchain have solution for that --> **lazy loading**

## Load vs Lazy load
1. load()
* Eager Loading (loads everythings at once)
* Return a List of Document obj
* Loads all Documents immediately into memory.
* Best when
* * The number of documents is small.
* * You want everythings loaded upfront.

2. lazy_load()
* Lazy_loading(loads on demand).
* Return A **generator of Document** objects.
* Documents are not all loaded at once: they're fetched one at a time as needed
* best when: 
* * You're dealing with large Documents or lots of files 
* * You want to stream processing (eg. chunking, embedding) without using lots of memory. 


## (WebBaseLoader)
webbaseLoader is a document loader in langchain used to load and extract text content from web page (url).

It uses **BeatifulSoup** under the hood to parser HTML and extract visible text.

* beatifulSoup bassically fetch data from html tags and not take those tags

When to Use:
* For blogs, news articles,or public website where the content is primarily  text-based and static


*** here we do two things first request to that server will return that html page and then using beatifulsoup we try to understand that html page and convert them into texture format.
## Limitations:
* Doesn't handle javascripts-heavy page well (use SeleniumURLLoader for that ).
* Load only static content (what's in the HTML, not when loads after the page renders).


# one facility is that you can give list of urls then you will be gotten list of documents object

##### application which you sould try: 
--> chrome plug-in ;; when a user open any page using api we load that page info using WebBaseLoader so user can search about that product


## (CSVLoader)
--> CSVLoader is a document loader used to load CSV files into LangChain Document objects one per row, by default. --> note: one row --> one document object




### note langchain also has given that you can make you own cutume loader ""using python class"" have to inheritent "BaseLoader" class