## memory (langchain) component we will study in langgraph

## now we are gonna start to make Rag application using Langchain

- there are lot of components in rag base application , one of them is --> **Document loaders**

RAG is a technique that **combines information** (some other datasets particularly about and business) retrieval with language generation(llm), where a model retriveves relavant documents from a knowledgement base and then uses them as context to generate accurate and grounded responses.

Benefits of using RAG

1. Use of up-to-date information
2. Better privacy
3. No limit of document size (we divide those in chunkes)

eg;; let suppose we want to know current affare so most probabilly our llm will not give it's response bz it was trained any past time

--> ask about your personal data (like ask them about your person 100days before email)

## so all those situation where llm does not have data to response you , on those situation we used rag base application

## what we does :

--> we provide **external knowledge** base to our llm

--> now if a query come to llm and it does not know about that then it can go to that external knowledge to check is this context there.

## Rag components

-> Document Loaders
-> Text splitters
-> vector Database
-> Retrievers

# (we make any complex rag base application using these component)

## today is about Document loaders --> using it we can easily load document from any source

## Document loaders (in langchain there are 100+ document loaders)

impossible to learn all --> so --> we try to know **main concept**

## and 4 most useable document loaders

1. TextLoader
2. PyPDFLoader
3. WebBaseLoader
4. CSVLoader

## Document Loaders in Langchain::

document loader in langchain used to load data from various sources into a standardized format (usually as Document objects), which can then be used for Chunking, embedding, retrieval, and generation,

eg: so for rag application we need data and need to load it, and data can exsist at different sources
data can be pdf, text file , at any database, at any cloud ;; what our focus is to retrieve data from the source with a **good format** so that we can use it other component of langchain;; so you fetch data at any place it will show like a document format always

this is document format:

Document (
page_content= "The actual text content",
metadata = {"source":"filename.pdf", ...}
)

## Notes all document loaders are at lanchain_community

## TextLoader

TextLoader is a simple and commonly used document loader in LangChain that reads plain text (.txt) files and converts them into langchain document object

Use Case

- Ideal for loading chat logs, scraped text, transcripts, code snippeds, or any plain text data into a langchain pipeline

Limitation

- Works only with .txt files

## steps

1. make loader object
2. inside it as input you have to give the path of that .txt file

## Most userful Loader --> ## PyPDFLoader

-> PyPDFLoader is a document loader in langchain used to load content from PDF file and convert each page into document object

[
Document(page_content= "Text from page 1", metadata= {"page":0, "source":"file.pdf"}),
Document(page_cotent= "Text from page 2", metadata={"page":1, "source":"file.pdf"}),
......
]

Limitations:

- It uses the PyPDF library under the hood -- not great with scanned PDFs(which has photos etc) or complex layouts.

25 page pdf --> PyPDF --> list of 25 Documents object

Since PypdfLoader good for text pdf ;; but there some good loader for scanned pdf

eg:
pdfs with tables/columns --> PDFPlumberLoader
Scanned/Image PDFs --> UnstrucredPDFLoader or AmazonTextractPDFLoader
need layout and Image data --> PyMuPDFLoader
Want best structure extraction --> UnstructuredPDFLoader
