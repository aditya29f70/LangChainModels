# for checking how you splitter splitting you text use this site to check you only need to put you text and choose model --> chunkviz.up.railway.app

## Text splitting
-> Text splitting is the process of breaking large chunks of text (like articles, pdfs, HTML pages, or books) into smaller, manageable pleces (chunks) that an llm can handle effectively.


(Large Text) ---> (Chunks) 

## that operator which does these kinds of works is call **text spliiter**

* llm output quality will increase if you give these chunks instead give the whole text file

## reason behind using text splitter

* Overcomig model limitations: Many embedding models and language models have maximum input size constraints. splitting allows us to process documents that would otherwise exceed these limits.

* Downstream tasks - Text Splitting improve nearly every LLM powered task

Task          | why splitting Helps
1. Embedding  | Short Chunks yield more accurate vectors
2. Semantic Search | Search results point to focused info, not noise
3. Summarization   | prevents hallucination and topic drift (sometime it will start to give unrelated things which will not happens if you use text-splitting)

* Optimizing computational resources : working with smaller chunks of text can be more memory-efficient allow for better parallelization of processing task.

## we will be studing four diff kind of text splitters in langchian
1. length based
2. Text structure based
3. Document Structure based
4. Semantic Meaning Based

## 1. length based 
here size of the chunk is decided (you can decide it according to it's number of charactors or number tokens it's up to you)

## dis-advantage of this splitter
--> it don't see linguestic structure of your text before splitting nor grammar and sementic meaning 

* how to use it in langchain --> we have a direct class Charactor_text_splitter

* params
1. chunk_size
2. chunk_overlap --> what it means;; it identify how many char will be overlap bw two chunks

* now question what is benifit that we will be getting you we use chunk_overlap by that some context meaning of sentence mainten , if a chunk start showing overlap char with it next chunk what would be great to main context meaning;; this is assumation that 10-20% chunk overlap would be good if you want to main chunk context meaning mainten for min 100 chunk size
3. separator=""


## (2. Text-structured Based splitter)

it knows that text are structured , first we have paragraph -> inside it we have sentences -> structured words --> char

## here we are going to study RecursiveChractorTextSplitter for structured splitting (one of the most used technics)

# how it works
--> we have decided some seperator before like for paragraph we have '\n\n' , for line change '\n', for words one space ' ', for char '',

--> RecursiveChar..splitter first try to use \n\n for make chunks (or chunks as a paragraph) , if it fall to chunks according to paragraphs then it move to chunks according to \n or sentence;; lly if it fall to make chunks according to chunks then it move to ' ' (space) or according to words etc

--> it also optimise after getting the words level chunks ;;eg if we took chunks size=10 , then it will go at the word level chunks and now it will start optimizing or joing these words untill we don't get a chunks which size <10 and not chances to add any other word

--> note (spaces) also count as char
--> it is better than CharactorBaseSplitting (bz structure base splitter always try to chunks text such that it will not cut the sentance)

--> as you increase chunk_size it will try to make chunsk as words --> sentence --> increase size --> according to paragraph

--> lly if you decreasing chunk_size then it will make chunks as paragraph --> sentence --> words --> still decrease char


## but you are going to take a good number then it can splitter you text perfectly


## (3. Document-Structured-Based) text splitter

--> what if you have documents which do not have plan text (english,hindi) , it is written entirely in diff language;; like you have some pic of code and you have to process it using llm ( it is a text but not normal text) bz we can't splitte it as normal  text

--> so we splitte it using certain keywords ;;eg: here also we use RecursiveCharacterTextSplitter but diff only is here we use **diff kind of seperators**

eg:some code part in the document or markdowns like thing in the docs: for splitting python code we use these kind of splitters; see pic 3
1. so if documents has **markdows** then we use --> RecursiveCharactorTextSplitter + Markdown splitter

2. lly if documents has codes(python) --> RecursiveCharactorTextSplitter + python splitter

* you have to just fixed that chunk_size


## (4. Semantic meaning Based)
### there are certain senorio where both major splitter (length-base-text-splitter, structure-base-text-splitter) failed to splitte text

